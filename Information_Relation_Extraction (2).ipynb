{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHfQMjDnlACs"
      },
      "source": [
        "# Assignment 3 - CT5120/CT5146\n",
        "\n",
        "### Instructions:\n",
        "- Complete all the tasks below and upload your submission as a Python notebook on Blackboard with the filename “`StudentID_Lastname.ipynb`” before **23:59** on **December 31, 2021**. Please note that there will be no further extensions to this deadline and we highly encourage you to submit this assignment before Semester 1 exams.\n",
        "- This is an individual assignment, you **must not** work with other students to complete this assessment.\n",
        "- The assignment is worth $100$ marks and constitutes 19% of the final grade. The breakdown of the marking scheme for each task is as follows:\n",
        "\n",
        "|           | Task | Marks |\n",
        "| :---      | :-----| -----:|\n",
        "| Task 1    | Pre-processing |   15 |\n",
        "| Task 2    | Named Entity Recognition |    10 |\n",
        "| Task 3    | Information / Relation Extraction (I) | 30 |\n",
        "| Task 4    | Information / Relation Extraction (II) | 15 |\n",
        "| Task 5    | Combining information in the output   | 5 |\n",
        "| Task 6    | Evaluation (I) | 15 |\n",
        "| Task 7    | Evaluation (II) | 10 |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEpjx2qKnyBl"
      },
      "source": [
        "---\n",
        "\n",
        "## Information Extraction and Relation Extraction\n",
        "\n",
        "In the following tasks you will write code to perform **_information extraction_** and **_relation extraction_** across a collection of documents in `movies.zip`.\n",
        "\n",
        "The zip archive contains 100 files, out of which 50 are plaintext documents and other 50 contain data structured as JSON.\n",
        "Each plaintext document contains a text description of a movie taken from the English version of Wikipedia, while each JSON document contains *gold-standard* labels (also called *reference* labels) stored as key-value pairs for the entities and relations for each document.\n",
        "\n",
        "You are only allowed to use the given documents and labels and **must not** use any other external sources of data for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64euw8hXygah"
      },
      "source": [
        "---\n",
        "\n",
        "Download and unarchive `movies.zip` from Blackboard and place it in the same location as this notebook or uncomment the code cell below to get the data in a directory called `movies` and also place it automatically in the same location as this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OXzoZVNZyevs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5bfa4cd-31dd-4ebe-e8cd-158fba28b582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-30 15:25:58--  https://drive.google.com/uc?export=download&id=1L6NcSGkubNJaL6xSnYEZZKSrlyXq1AbB\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.31.102, 74.125.31.139, 74.125.31.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.31.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-90-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i8u21mkp3jgee5vne2c9ad3siu68c2u6/1640877900000/04741348677416923358/*/1L6NcSGkubNJaL6xSnYEZZKSrlyXq1AbB?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-12-30 15:26:00--  https://doc-04-90-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i8u21mkp3jgee5vne2c9ad3siu68c2u6/1640877900000/04741348677416923358/*/1L6NcSGkubNJaL6xSnYEZZKSrlyXq1AbB?e=download\n",
            "Resolving doc-04-90-docs.googleusercontent.com (doc-04-90-docs.googleusercontent.com)... 173.194.218.132, 2607:f8b0:400c:c14::84\n",
            "Connecting to doc-04-90-docs.googleusercontent.com (doc-04-90-docs.googleusercontent.com)|173.194.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94432 (92K) [application/zip]\n",
            "Saving to: ‘movies.zip’\n",
            "\n",
            "movies.zip          100%[===================>]  92.22K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-12-30 15:26:00 (111 MB/s) - ‘movies.zip’ saved [94432/94432]\n",
            "\n",
            "Archive:  movies.zip\n",
            "   creating: movies/\n",
            "  inflating: movies/50.doc.txt       \n",
            "  inflating: movies/40.doc.txt       \n",
            "  inflating: movies/32.doc.txt       \n",
            "  inflating: movies/22.doc.txt       \n",
            "  inflating: movies/14.info.json     \n",
            "  inflating: movies/35.info.json     \n",
            "  inflating: movies/21.info.json     \n",
            "  inflating: movies/19.info.json     \n",
            "  inflating: movies/49.doc.txt       \n",
            "  inflating: movies/42.info.json     \n",
            "  inflating: movies/38.info.json     \n",
            "  inflating: movies/14.doc.txt       \n",
            "  inflating: movies/04.doc.txt       \n",
            "  inflating: movies/33.info.json     \n",
            "  inflating: movies/49.info.json     \n",
            "  inflating: movies/48.doc.txt       \n",
            "  inflating: movies/27.info.json     \n",
            "  inflating: movies/05.doc.txt       \n",
            "  inflating: movies/15.doc.txt       \n",
            "  inflating: movies/06.info.json     \n",
            "  inflating: movies/12.info.json     \n",
            "  inflating: movies/41.doc.txt       \n",
            "  inflating: movies/44.info.json     \n",
            "  inflating: movies/50.info.json     \n",
            "  inflating: movies/23.doc.txt       \n",
            "  inflating: movies/33.doc.txt       \n",
            "  inflating: movies/15.info.json     \n",
            "  inflating: movies/01.info.json     \n",
            "  inflating: movies/28.doc.txt       \n",
            "  inflating: movies/38.doc.txt       \n",
            "  inflating: movies/20.info.json     \n",
            "  inflating: movies/17.doc.txt       \n",
            "  inflating: movies/07.doc.txt       \n",
            "  inflating: movies/34.info.json     \n",
            "  inflating: movies/18.info.json     \n",
            "  inflating: movies/31.doc.txt       \n",
            "  inflating: movies/21.doc.txt       \n",
            "  inflating: movies/43.doc.txt       \n",
            "  inflating: movies/43.info.json     \n",
            "  inflating: movies/39.info.json     \n",
            "  inflating: movies/20.doc.txt       \n",
            "  inflating: movies/30.doc.txt       \n",
            "  inflating: movies/26.info.json     \n",
            "  inflating: movies/32.info.json     \n",
            "  inflating: movies/42.doc.txt       \n",
            "  inflating: movies/48.info.json     \n",
            "  inflating: movies/13.info.json     \n",
            "  inflating: movies/07.info.json     \n",
            "  inflating: movies/39.doc.txt       \n",
            "  inflating: movies/29.doc.txt       \n",
            "  inflating: movies/45.info.json     \n",
            "  inflating: movies/06.doc.txt       \n",
            "  inflating: movies/16.doc.txt       \n",
            "  inflating: movies/37.info.json     \n",
            "  inflating: movies/23.info.json     \n",
            "  inflating: movies/13.doc.txt       \n",
            "  inflating: movies/03.doc.txt       \n",
            "  inflating: movies/02.info.json     \n",
            "  inflating: movies/16.info.json     \n",
            "  inflating: movies/40.info.json     \n",
            "  inflating: movies/35.doc.txt       \n",
            "  inflating: movies/25.doc.txt       \n",
            "  inflating: movies/47.doc.txt       \n",
            "  inflating: movies/04.info.json     \n",
            "  inflating: movies/10.info.json     \n",
            "  inflating: movies/31.info.json     \n",
            "  inflating: movies/24.doc.txt       \n",
            "  inflating: movies/34.doc.txt       \n",
            "  inflating: movies/46.doc.txt       \n",
            "  inflating: movies/25.info.json     \n",
            "  inflating: movies/09.info.json     \n",
            "  inflating: movies/02.doc.txt       \n",
            "  inflating: movies/12.doc.txt       \n",
            "  inflating: movies/46.info.json     \n",
            "  inflating: movies/28.info.json     \n",
            "  inflating: movies/22.info.json     \n",
            "  inflating: movies/09.doc.txt       \n",
            "  inflating: movies/19.doc.txt       \n",
            "  inflating: movies/36.info.json     \n",
            "  inflating: movies/44.doc.txt       \n",
            "  inflating: movies/17.info.json     \n",
            "  inflating: movies/03.info.json     \n",
            "  inflating: movies/36.doc.txt       \n",
            "  inflating: movies/26.doc.txt       \n",
            "  inflating: movies/10.doc.txt       \n",
            "  inflating: movies/41.info.json     \n",
            "  inflating: movies/11.info.json     \n",
            "  inflating: movies/01.doc.txt       \n",
            "  inflating: movies/11.doc.txt       \n",
            "  inflating: movies/05.info.json     \n",
            "  inflating: movies/24.info.json     \n",
            "  inflating: movies/30.info.json     \n",
            "  inflating: movies/18.doc.txt       \n",
            "  inflating: movies/08.info.json     \n",
            "  inflating: movies/08.doc.txt       \n",
            "  inflating: movies/29.info.json     \n",
            "  inflating: movies/45.doc.txt       \n",
            "  inflating: movies/27.doc.txt       \n",
            "  inflating: movies/37.doc.txt       \n",
            "  inflating: movies/47.info.json     \n"
          ]
        }
      ],
      "source": [
        "!if test -f \"movies.zip\"; then rm \"movies.zip\"; fi\n",
        "!if test -d \"movies/\"; then rm -rf \"movies/\"; fi\n",
        "!wget \"https://drive.google.com/uc?export=download&id=1L6NcSGkubNJaL6xSnYEZZKSrlyXq1AbB\" -O \"movies.zip\"\n",
        "!unzip \"movies.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm1emJILzF5K"
      },
      "source": [
        "---\n",
        "\n",
        "## Reading Data\n",
        "\n",
        "Place the unzipped `movies` directory in the same location as this notebook and run the following code cell to read the plaintext and JSON documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P5hzct-HzUvJ"
      },
      "outputs": [],
      "source": [
        "######### DO NOT EDIT THIS CELL #########\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "documents = []   # store the text documents as a list of strings\n",
        "labels = []      # store the gold-standard labels as a list of dictionaries\n",
        "\n",
        "for idx in range(50):\n",
        "  with open(os.path.join('movies', str(idx+1).zfill(2) + '.doc.txt')) as f:\n",
        "    doc = f.read().strip()\n",
        "  with open(os.path.join('movies', str(idx+1).zfill(2) + '.info.json')) as f:\n",
        "    label = json.load(f)\n",
        "\n",
        "  documents.append(doc)\n",
        "  labels.append(label)\n",
        "\n",
        "assert len(documents) == 50\n",
        "assert len(labels) == 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnmnLhDyj2eG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nPCKvyYFj0zG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fec4ba5-421f-4274-a1ea-58c2019672b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Load the libraries which might be useful\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('all', quiet=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899-kd7LmlFp"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 1: Document Pre-processing (15 Marks)\n",
        "Write a function that takes a document and returns a list of sentences with part-of-speech tags.\n",
        "\n",
        "The expected output is a list of tagged sentences where each tagged sentence is a list containing `(token, tag)` pairs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dB8R43AklZxO"
      },
      "outputs": [],
      "source": [
        "def ie_preprocess(document):\n",
        "  '''Return a list of sentences tagged with part-of-speech tags for the given document.'''\n",
        "\n",
        "  tagged_sentences = []\n",
        "\n",
        "\n",
        "  # Step 1: Sentence segmentation.\n",
        "  sentences = nltk.sent_tokenize(document)\n",
        "  \n",
        "  # Step 2: Tokenize sentences into words.\n",
        "  tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "  \n",
        "  # Step 3: POS tagging.\n",
        "  tagged_sentences = [nltk.pos_tag(sent) for sent in tokenized_sentences]\n",
        "  \n",
        "    \n",
        "  \n",
        "  return tagged_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KJLD-AMMvdq"
      },
      "source": [
        "Run the cell below to check if the output is formatted correctly.\n",
        "\n",
        "Expected output: `[('It', 'PRP'), ('received', 'VBD'), ('ten', 'JJ'), ('Oscar', 'NNP'), ('nominations', 'NNS'), ('(', '('), ('including', 'VBG'), ('Best', 'NNP'), ('Picture', 'NN'), (')', ')'), (',', ','), ('winning', 'VBG'), ('seven', 'CD'), ('.', '.')]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9sEQYa3TBDYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3730240f-85f3-4904-a25b-415b673396ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('It', 'PRP'),\n",
              " ('received', 'VBD'),\n",
              " ('ten', 'JJ'),\n",
              " ('Oscar', 'NNP'),\n",
              " ('nominations', 'NNS'),\n",
              " ('(', '('),\n",
              " ('including', 'VBG'),\n",
              " ('Best', 'NNP'),\n",
              " ('Picture', 'NN'),\n",
              " (')', ')'),\n",
              " (',', ','),\n",
              " ('winning', 'VBG'),\n",
              " ('seven', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# check output for Task 1\n",
        "ie_preprocess(documents[0])[-10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgEPCLXmq8bC"
      },
      "source": [
        "## Task 2: Named Entity Recognition (10 Marks)\n",
        "\n",
        "Write a function that returns a list of all the named entities in a given document. The document here is structured as a list of sentences and tagged with part-of-speech tags.\n",
        "\n",
        "Hint: Set `binary = True` while calling the `ne_chunk` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qHKjz5TKp5uM"
      },
      "outputs": [],
      "source": [
        "def find_named_entities(tagged_document):\n",
        "  '''Return a list of all the named entities in the given tagged document.'''\n",
        "  \n",
        "  named_entities = []\n",
        "\n",
        "  for sentu in tagged_document:\n",
        "    tree = nltk.ne_chunk(sentu, binary=True)\n",
        "    for subtree in tree.subtrees():\n",
        "      if subtree.label() == 'NE':\n",
        "        entity = \"\"\n",
        "        for leaf in subtree.leaves():\n",
        "          entity = entity + leaf[0] + \" \"\n",
        "        named_entities.append(entity.strip())\n",
        "             \n",
        "\n",
        "  return named_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvZNyV-ENDZc"
      },
      "source": [
        "Run the cell below to check if the output is formatted correctly.\n",
        "\n",
        "The output values might not match exactly, but should look similar to: `['Star Wars', 'Star Wars', 'New Hope', 'American', 'George Lucas', 'Lucasfilm', ...]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lnlqsKg7sk29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e69ae55-ceae-402d-e42b-06f5d8af988e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Star Wars',\n",
              " 'Star Wars',\n",
              " 'New Hope',\n",
              " 'American',\n",
              " 'George Lucas',\n",
              " 'Lucasfilm',\n",
              " 'Century Fox',\n",
              " 'Mark Hamill',\n",
              " 'Harrison Ford',\n",
              " 'Carrie Fisher']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# check output for Task 2\n",
        "tagged_document = ie_preprocess(documents[0]) # pre-process the first document\n",
        "find_named_entities(tagged_document)[:10]     # display the first 10 named entities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_named_entities(tagged_document)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46aGfaPUajrt",
        "outputId": "9574e596-1cc0-42c0-f3a4-a37c304c13d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Star Wars',\n",
              " 'Star Wars',\n",
              " 'New Hope',\n",
              " 'American',\n",
              " 'George Lucas',\n",
              " 'Lucasfilm',\n",
              " 'Century Fox',\n",
              " 'Mark Hamill',\n",
              " 'Harrison Ford',\n",
              " 'Carrie Fisher']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmpuu0yvwI_X"
      },
      "source": [
        "## Task 3: Information / Relation Extraction (I) (30 Marks)\n",
        "\n",
        "Choose any **three** relations out of the following and write functions to extract them from a given document.\n",
        "\n",
        "* **Title**\n",
        "* **Language**\n",
        "* **Starring**\n",
        "* **Release date**\n",
        "* **Cinematography**\n",
        "* **Dialogue by**\n",
        "* **Directed by**\n",
        "* **Edited by**\n",
        "* **Music by**\n",
        "* **Narrated by**\n",
        "* **Produced by**\n",
        "* **Screenplay by**\n",
        "* **Story by**\n",
        "* **Written by**\n",
        "* **Production companies**\n",
        "* **Distribution companies**\n",
        "* **Budget**\n",
        "* **Box office**\n",
        "\n",
        "\n",
        "The functions you define here must take as input a string called `document` and return the information/relation extracted as a list. You can explain your approach with comments along with your code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Yw8YQAr-wwFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301be289-883f-4a99-ae2b-9abb771f1104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NE: 'George/NNP Lucas/NNP'] ',/, produced/VBN by/IN' [NE: 'Lucasfilm/NNP']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lucasfilm', 'george_lucas']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "# relation 1 \n",
        "def relation1(doc):\n",
        "\n",
        "  tokenized_sent = nltk.sent_tokenize(doc)\n",
        "  tagged_sent = [nltk.word_tokenize(sent) for sent in tokenized_sent]\n",
        "  tagged_sent = [nltk.pos_tag(sent) for sent in tagged_sent]\n",
        "\n",
        "  output_prod = []\n",
        "\n",
        "  for sent in tagged_sent:\n",
        "    # Define X, Y, and \\alpha\n",
        "    subjclass = 'NE'\n",
        "    objclass = 'NE'\n",
        "    pattern = re.compile(r'.*Produce.*', re.IGNORECASE)\n",
        "\n",
        "    # Group a chunk structure into a list of 'semi-relations'.\n",
        "\n",
        "    chunked = nltk.ne_chunk(sent, binary=True) \n",
        "    pairs = nltk.sem.relextract.tree2semi_rel(chunked)\n",
        "\n",
        "    # Convert 'semi-relations' into a dictionary which stores information \n",
        "    # about the subject and object NEs plus the filler between them.\n",
        "    reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])\n",
        "\n",
        "    # Filter relevant relations by matching the regexp pattern.\n",
        "    relfilter = lambda x: (x['subjclass'] == subjclass and\n",
        "                              pattern.match(x['filler']) and\n",
        "                              x['objclass'] == objclass)\n",
        "    \n",
        "    rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "    # Print the relations found in the text.\n",
        "    for rel in rels:\n",
        "      print(nltk.sem.relextract.rtuple(rel))\n",
        "\n",
        "    if len(rels) > 0:\n",
        "      output_prod.append(rels[0]['objsym'])\n",
        "      output_prod.append(rels[0]['subjsym'])\n",
        "  return output_prod\n",
        "\n",
        "relation1(documents[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[2]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "wnrRyxD7qS7K",
        "outputId": "afacd40a-1cbc-44b6-eebe-f79e36a08646"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The Dark Knight is a 2008 superhero film directed, produced, and co-written by Christopher Nolan. Based on the DC Comics character Batman, the film is the second installment of Nolan\\'s The Dark Knight Trilogy and a sequel to 2005\\'s Batman Begins, starring Christian Bale and supported by Michael Caine, Heath Ledger, Gary Oldman, Aaron Eckhart, Maggie Gyllenhaal, and Morgan Freeman. In the film, Bruce Wayne / Batman (Bale), Police Lieutenant James Gordon (Oldman) and District Attorney Harvey Dent (Eckhart) form an alliance to dismantle organized crime in Gotham City, but are menaced by an anarchistic mastermind known as the Joker (Ledger), who seeks to undermine Batman\\'s influence and throw the city into anarchy. Nolan\\'s inspiration for the film was the Joker\\'s comic book debut in 1940, the 1988 graphic novel The Killing Joke, and the 1996 series The Long Halloween, which retold Harvey Dent\\'s origin. The \"Dark Knight\" nickname was first applied to Batman in Batman #1 (1940), in a story written by Bill Finger. The Dark Knight was filmed primarily in Chicago, as well as in several other locations in the United States, the United Kingdom, and Hong Kong. The film was the first mainstream feature to partially utilize IMAX 70 mm cameras, with Nolan using them for 28 minutes of the film, including the Joker\\'s first appearance. Warner Bros. initially created a viral marketing campaign for The Dark Knight, developing promotional websites and trailers highlighting screenshots of Ledger as the Joker. Ledger died on January 22, 2008, some months after he completed filming and six months before the film\\'s release from a toxic combination of prescription drugs, leading to intense attention from the press and movie-going public. Considered one of the best films of its decade and one of the greatest and most influential superhero films of all time, the film received critical acclaim for its screenplay, visual effects, musical score, mature themes, performances (particularly Ledger\\'s), cinematography, action sequences and direction. The film also set numerous records during its theatrical run. The Dark Knight appeared on 287 critics\\' top-ten lists, more than any other film of 2008 with the exception of WALL-E, and more critics (77) named The Dark Knight the best film released that year. With over $1 billion in revenue worldwide, it became the fourth-highest-grossing film at the time, and highest-grossing film of 2008; it also set the record for highest-grossing domestic opening with $158 million, a record it held for three years. At the 81st Academy Awards, the film received eight nominations; it won the award for Best Sound Editing and Ledger was posthumously awarded Best Supporting Actor. In 2020, the film was selected for preservation in the United States National Film Registry by the Library of Congress for being \"culturally, historically, or aesthetically significant\", becoming the second DC superhero film after 1978\\'s Superman to earn the honor. The Dark Knight Rises, the final film in the trilogy, was released on July 20, 2012.'"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "16p4KMlVyQU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073fd82e-b295-45e4-f868-f3c45f3ed69c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NE: 'American/JJ'] 'epic/NN biographical/JJ black/JJ comedy/NN crime/NN film/NN directed/VBN by/IN' [NE: 'Martin/NNP Scorsese/NNP']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['martin_scorsese', 'american']"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "# relation 2 \n",
        "def relation2(doc):\n",
        "\n",
        "  tokenized_sent = nltk.sent_tokenize(doc)\n",
        "  tagged_sent = [nltk.word_tokenize(sent) for sent in tokenized_sent]\n",
        "  tagged_sent = [nltk.pos_tag(sent) for sent in tagged_sent]\n",
        "\n",
        "  output_prod = []\n",
        "\n",
        "  for sent in tagged_sent:\n",
        "    # Define X, Y, and \\alpha\n",
        "    subjclass = 'NE'\n",
        "    objclass = 'NE'\n",
        "    pattern = re.compile(r'.*Direct.*', re.IGNORECASE)\n",
        "\n",
        "    # Group a chunk structure into a list of 'semi-relations'.\n",
        "\n",
        "    chunked = nltk.ne_chunk(sent, binary=True) \n",
        "    pairs = nltk.sem.relextract.tree2semi_rel(chunked)\n",
        "\n",
        "    # Convert 'semi-relations' into a dictionary which stores information \n",
        "    # about the subject and object NEs plus the filler between them.\n",
        "    reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])\n",
        "\n",
        "    # Filter relevant relations by matching the regexp pattern.\n",
        "    relfilter = lambda x: (x['subjclass'] == subjclass and\n",
        "                              pattern.match(x['filler']) and\n",
        "                              x['objclass'] == objclass)\n",
        "    \n",
        "    rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "    # Print the relations found in the text.\n",
        "    for rel in rels:\n",
        "      print(nltk.sem.relextract.rtuple(rel))\n",
        "\n",
        "    if len(rels) > 0:\n",
        "      output_prod.append(rels[0]['objsym'])\n",
        "      output_prod.append(rels[0]['subjsym'])\n",
        "  return output_prod\n",
        "\n",
        "relation2(documents[10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "CuyRYS6SGufi",
        "outputId": "b59f4825-39d8-4998-b8e1-335539cfb717"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Star Wars: The Rise of Skywalker (also known as Star Wars: Episode IX - The Rise of Skywalker) is a 2019 American epic space opera film produced, co-written, and directed by J. J. Abrams. Produced by Lucasfilm and Abrams\\' production company Bad Robot Productions, and distributed by Walt Disney Studios Motion Pictures, it is the third installment of the Star Wars sequel trilogy, following The Force Awakens (2015) and The Last Jedi (2017), and the final episode of the nine-part \"Skywalker saga\". Its ensemble cast includes Carrie Fisher, Mark Hamill, Adam Driver, Daisy Ridley, John Boyega, Oscar Isaac, Anthony Daniels, Naomi Ackie, Domhnall Gleeson, Richard E. Grant, Lupita Nyong\\'o, Keri Russell, Joonas Suotamo, Kelly Marie Tran, Ian McDiarmid, and Billy Dee Williams. The Rise of Skywalker follows Rey, Finn, and Poe Dameron as they lead the Resistance\\'s final stand against Supreme Leader Kylo Ren and the First Order, who are aided by the return of the deceased Galactic Emperor, Palpatine. Following initial reports that The Last Jedi director Rian Johnson would write the script for Episode IX, in August 2015, Colin Trevorrow was hired to direct and to write a script with his collaborator Derek Connolly; both ultimately retain story credit with Abrams and Chris Terrio. In September 2017, Trevorrow left the project following creative differences with producer Kathleen Kennedy, and Abrams returned as director. John Williams, composer for the previous episodic films, returned to compose the score-his final score for the franchise. Principal photography began in August 2018 at Pinewood Studios in England and wrapped in February 2019, with post-production completed in November 2019. With an estimated budget of $275 million, it is one of the most expensive films ever made. It premiered in Los Angeles on December 16, 2019, and was released in the United States on December 20. It received mixed reviews from critics, who praised the acting, action sequences, musical score, and visual effects, but criticized the story, pacing, and its perceived departures from the plot and themes of The Last Jedi; many deemed it to be a disappointing conclusion to the episodic saga. It grossed over $1.074 billion worldwide, becoming the seventh-highest-grossing film of 2019; although it was the lowest-grossing installment of the trilogy, and turned an estimated net profit of $300 million. It received three nominations at the 92nd Academy Awards (Best Original Score, Best Visual Effects, and Best Sound Editing) as well as three at the 73rd British Academy Film Awards (also Best Special Visual Effects, Best Original Music, and Best Sound).'"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "x-LRnjy810ZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4361e9db-c697-42c9-963f-b2ae4ea3a0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NE: 'Martin/NNP Scorsese/NNP'] 'and/CC written/VBN by/IN' [NE: 'Terence/NNP Winter/NNP']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['terence_winter', 'martin_scorsese']"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "# relation 3 \n",
        "def relation3(doc):\n",
        "\n",
        "  tokenized_sent = nltk.sent_tokenize(doc)\n",
        "  tagged_sent = [nltk.word_tokenize(sent) for sent in tokenized_sent]\n",
        "  tagged_sent = [nltk.pos_tag(sent) for sent in tagged_sent]\n",
        "\n",
        "  output_prod = []\n",
        "\n",
        "  for sent in tagged_sent:\n",
        "    # Define X, Y, and \\alpha\n",
        "    subjclass = 'NE'\n",
        "    objclass = 'NE'\n",
        "    pattern = re.compile(r'.*Written.*', re.IGNORECASE)\n",
        "\n",
        "    # Group a chunk structure into a list of 'semi-relations'.\n",
        "\n",
        "    chunked = nltk.ne_chunk(sent, binary=True) \n",
        "    pairs = nltk.sem.relextract.tree2semi_rel(chunked)\n",
        "\n",
        "    # Convert 'semi-relations' into a dictionary which stores information \n",
        "    # about the subject and object NEs plus the filler between them.\n",
        "    reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])\n",
        "\n",
        "    # Filter relevant relations by matching the regexp pattern.\n",
        "    relfilter = lambda x: (x['subjclass'] == subjclass and\n",
        "                              pattern.match(x['filler']) and\n",
        "                              x['objclass'] == objclass)\n",
        "    \n",
        "    rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "    # Print the relations found in the text.\n",
        "    for rel in rels:\n",
        "      print(nltk.sem.relextract.rtuple(rel))\n",
        "\n",
        "    if len(rels) > 0:\n",
        "      output_prod.append(rels[0]['objsym'])\n",
        "      output_prod.append(rels[0]['subjsym'])\n",
        "  return output_prod\n",
        "\n",
        "relation3(documents[10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuJmr-eKvrQ3"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 4: Information / Relation Extraction (II)  (15 Marks)\n",
        "\n",
        "Identify one other relation of your choice, besides the ones mentioned in the previous task, and write a function to extract it. \n",
        "\n",
        "The function you define here must take as input a string called `document` and return the information/relations extracted as a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "kncUM3pHvyAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba58536-78f5-4c4a-d529-2f32d96470a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NE: 'Star/NN Wars/NNS'] ':/: Episode/NNP IX/NNP -/: The/DT Rise/NN of/IN' [NE: 'Skywalker/NNP']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['skywalker', 'star_wars']"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "def relation(doc):\n",
        "\n",
        "  tokenized_sent = nltk.sent_tokenize(doc)\n",
        "  tagged_sent = [nltk.word_tokenize(sent) for sent in tokenized_sent]\n",
        "  tagged_sent = [nltk.pos_tag(sent) for sent in tagged_sent]\n",
        "\n",
        "  output_prod = []\n",
        "\n",
        "  for sent in tagged_sent:\n",
        "    # Define X, Y, and \\alpha\n",
        "    subjclass = 'NE'\n",
        "    objclass = 'NE'\n",
        "    pattern = re.compile(r'.*episode.*', re.IGNORECASE)\n",
        "\n",
        "    # Group a chunk structure into a list of 'semi-relations'.\n",
        "\n",
        "    chunked = nltk.ne_chunk(sent, binary=True) \n",
        "    pairs = nltk.sem.relextract.tree2semi_rel(chunked)\n",
        "\n",
        "    # Convert 'semi-relations' into a dictionary which stores information \n",
        "    # about the subject and object NEs plus the filler between them.\n",
        "    reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])\n",
        "\n",
        "    # Filter relevant relations by matching the regexp pattern.\n",
        "    relfilter = lambda x: (x['subjclass'] == subjclass and\n",
        "                              pattern.match(x['filler']) and\n",
        "                              x['objclass'] == objclass)\n",
        "    \n",
        "    rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "    # Print the relations found in the text.\n",
        "    for rel in rels:\n",
        "      print(nltk.sem.relextract.rtuple(rel))\n",
        "\n",
        "    if len(rels) > 0:\n",
        "      output_prod.append(rels[0]['objsym'])\n",
        "      output_prod.append(rels[0]['subjsym'])\n",
        "  return output_prod\n",
        "\n",
        "# for x in documents:\n",
        "#   print(relation(x))\n",
        "relation(documents[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIfQCd_Y1x5B"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 5: Combining information in the output (5 Marks)\n",
        "\n",
        "Edit the function below to return a Python dictionary with the outputs from the functions defined in tasks $3 - 4$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "BE_8ptxp-1y4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02950a7e-338e-4de1-bf07-8e6155dc182d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NE: 'Trevorrow/NNP'] 'left/VBD the/DT project/NN following/VBG creative/JJ differences/NNS with/IN producer/NN' [NE: 'Kathleen/NNP Kennedy/NNP']\n",
            "[NE: 'Star/NN Wars/NNS'] ':/: Episode/NNP IX/NNP -/: The/DT Rise/NN of/IN' [NE: 'Skywalker/NNP']\n",
            "[NE: 'Star/NN Wars/NNS'] ':/: Episode/NNP IX/NNP -/: The/DT Rise/NN of/IN' [NE: 'Skywalker/NNP']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Directed by': [['kathleen_kennedy', 'trevorrow']],\n",
              " 'Produced by': [[]],\n",
              " 'Written by': [['skywalker', 'star_wars']],\n",
              " 'episode': [['skywalker', 'star_wars']]}"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "def extract_info(document):\n",
        "  '''Extract information and relations from a given document.'''\n",
        "\n",
        "  # Edit the output dict below and assign the values to keys by \n",
        "  # calling the appropriate functions from Tasks 3 and 4.\n",
        "  \n",
        "  # You can delete the keys for which you do not perform extraction in Task 3.\n",
        "  temp_1 = relation1(document)\n",
        "  temp_2 = relation2(document)\n",
        "  temp_3 = relation3(document)\n",
        "  temp_4 = relation(document)\n",
        "  output = {\n",
        "    ##### EDIT BELOW THIS LINE #####\n",
        "    \n",
        "    # For the relations you extract in Task 3, \n",
        "    # save the output in the appropriate key and delete rest of the keys.\n",
        "    \n",
        "    \n",
        "  \n",
        "    \"Directed by\": [temp_1],\n",
        "    \n",
        "    \"Produced by\": [temp_2],\n",
        "    \n",
        "    \"Written by\": [temp_3],\n",
        "   \n",
        "\n",
        "    # save the output from Task 4 here\n",
        "    \"episode\": [temp_4],\n",
        "\n",
        "    ##### EDIT ABOVE THIS LINE #####\n",
        "  }\n",
        "\n",
        "  return output\n",
        "\n",
        "\n",
        "# check output for the first document\n",
        "extract_info(documents[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHv5pRQ7BKJo"
      },
      "source": [
        "The output from the cell above should look something like the dictionary shown below. Overall values might be different, based on what four items you choose to extract in Tasks 3 and 4, but the structure should be similar.\n",
        "\n",
        "For example, if you choose to extract **Starring**, **Release Date**, **Box office**, and **Directed by**, then the output should look something like this for the first document:\n",
        "\n",
        "```javascript\n",
        "{\n",
        "  'Box office': ['$775 million'],\n",
        "  'Directed by': ['George Lucas'],\n",
        "  'Release date': ['May 25, 1977'],\n",
        "  'Starring': ['Mark Hamill', 'Harrison Ford', 'Carrie Fisher', \n",
        "               'Peter Cushing', 'David Prowse', 'James Earl Jones', ],\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDMhFQq4fBnf"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 6: Evaluation (I) (15 Marks)\n",
        "\n",
        "Write a function to evaluate the performance of Task $3$ using **Precision**, **Recall** and **F1** scores. Use the gold-standard labels provided in the JSON files to calculate these values.\n",
        "\n",
        "Please note that not all the information / relations mentioned in Task $3$ have associated labels for each and every movie in the JSON documents, i.e., some JSON documents will have certain keys-value pairs missing. For example, we have labels for *Budget* in 46 out of the 50 movies and in the remaining 4 documents, you will find that the key `Budget` is omitted from the JSON.\n",
        " \n",
        "Also keep in mind that we will further run this evaluation on a hidden test set containing similar movie descriptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "OvJ9OhnDe7ML"
      },
      "outputs": [],
      "source": [
        "def evaluate(labels, predictions):\n",
        "  '''\n",
        "  Evaluate the performance of relation extraction \n",
        "  using Precision, Recall, and F1 scores.\n",
        "\n",
        "  Args:\n",
        "    labels: A list containing gold-standard labels\n",
        "    predictions: A list containing information extracted from documents\n",
        "  Returns:\n",
        "    scores: A dictionary containing Precision, Recall and F1 scores \n",
        "            for the information/relations extracted in Task 3.\n",
        "  '''\n",
        "\n",
        "  assert len(predictions) == len(labels)\n",
        "\n",
        "  scores = {\n",
        "      'precision': 0.0, 'recall': 0.0, 'f1': 0.0\n",
        "  }\n",
        "\n",
        "  # calculate the precision, recall and f1 score over the information fields \n",
        "  # corresponding to Task 3 and store the result in the `scores` dict.\n",
        "\n",
        "  # your code goes here\n",
        "  # ...\n",
        "\n",
        "\n",
        "\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA39EbBCfRu6"
      },
      "source": [
        "---\n",
        "Run the cell below to calculate and display the evaluation scores for the 50 documents in `movies.zip`.\n",
        "\n",
        "You can consider the following as a baseline score. Your aim should be to score higher or atleast get as close as possible to these values.\n",
        "\n",
        "| Precision | Recall | F1    |\n",
        "| :---:     | :---:  | :---: |\n",
        "| 0.5       | 0.25   | 0.333 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRxOd4dIfRu-"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "# calculate evaluation score across all the 50 documents\n",
        "extracted_infos = []\n",
        "for document in documents:\n",
        "  extracted_infos.append(extract_info(document))\n",
        "\n",
        "scores = evaluate(labels, extracted_infos)\n",
        "\n",
        "pd.DataFrame([scores])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agNQPVqG5aoS"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 7: Evaluation (II) (10 Marks)\n",
        "\n",
        "Describe **two** challenges you encountered above or might encounter in the evaluation of *information extraction* or *relation extraction* tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdKI5J-fF1g"
      },
      "source": [
        "Edit this cell to write your answer below the line in no more than 100 words. No coding is required for this task.\n",
        "\n",
        "---\n",
        "\n",
        "> Delete this line and write your answer here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "nlp_assignment3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}